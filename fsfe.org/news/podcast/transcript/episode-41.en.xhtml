<?xml version="1.0" encoding="utf-8"?>
<html>
 <version>3</version>
<head>
<title>Transcript SFP#41</title>
</head>
<body>
  
<h1>SFP#41: Policy and EU: Recap of SFSCON</h1>

<p><a href="/news/podcast/episode-41.html">Back to the episode SFP#41</a></p>
<p>This is a transcript created with the Free Software tool Whisper. For more information and feedback reach out to <email mailto="yes">podcast@fsfe.org</email></p>

<pre class="transcript">
   <div class="content-centered"><h1 class="post-title"><a>SFP#41: Policy and EU: Recap of SFSCON</a></h1>

WEBVTT

00:00.000 --> 00:05.000
All right, then let's get started!

00:05.000 --> 00:07.000
Yay!

00:21.000 --> 00:24.000
Hello and welcome to the Software Freedom Podcast.

00:24.000 --> 00:28.000
This podcast is brought to you by the Free Software Foundation Europe.

00:29.000 --> 00:33.000
We are a charity that empowers users to control technology.

00:33.000 --> 00:36.000
And I'm here. I'm Bonnie Mehring.

00:36.000 --> 00:40.000
And I'm here today with my colleague, Alexander Sander.

00:40.000 --> 00:46.000
Alex, it's so nice that you made the time again for our monthly EU and policy episode.

00:46.000 --> 00:48.000
Thank you so much.

00:48.000 --> 00:51.000
Yeah, thanks for having me. Always a pleasure.

00:52.000 --> 00:57.000
So Alex, this time we will talk about the SFSCON,

00:57.000 --> 01:00.000
which has just happened this weekend.

01:00.000 --> 01:05.000
So you were there. I wasn't. I'm really sad that I missed it.

01:05.000 --> 01:10.000
But maybe next year, can you tell us a bit about what happened

01:10.000 --> 01:16.000
and what the conference is all about and why it's so important for the Free Software ecosystem?

01:16.000 --> 01:20.000
Absolutely. So the SFSCON is a very established conference.

01:20.000 --> 01:24.000
It was the 25th edition already this time.

01:24.000 --> 01:28.000
So it's, yeah, I said a very established conference.

01:28.000 --> 01:31.000
It happens in Italy, in Bolzano.

01:31.000 --> 01:36.000
So in South Tyrol and in the so-called NOI-Tech Park,

01:36.000 --> 01:41.000
which is also very lovely venue where people think around this technology

01:41.000 --> 01:45.000
and, yeah, in this regard also with Free Software.

01:45.000 --> 01:48.000
And the SFSCON is a Free Software conference,

01:48.000 --> 01:53.000
where around 1,000 people meet and discuss Free Software topics

01:53.000 --> 01:55.000
and present their projects.

01:55.000 --> 01:58.000
There's also attached to a data tone.

01:58.000 --> 02:01.000
And it's happening from Friday to Saturday.

02:01.000 --> 02:03.000
So it's a two-day conference.

02:03.000 --> 02:06.000
And it's very intense and very exciting talks.

02:06.000 --> 02:10.000
And normally it also comes with a dedicated topic.

02:10.000 --> 02:13.000
It's here, the main topic was ethics.

02:13.000 --> 02:16.000
So we talked a lot about Free Software and ethics.

02:16.000 --> 02:20.000
And that was super interesting to hear how other people look at this topic,

02:20.000 --> 02:25.000
how they work with this and what people are facing in this regard

02:25.000 --> 02:28.000
and from developers, maintainers, companies,

02:28.000 --> 02:33.000
but also the SFSFE and Geo's charities have been there.

02:33.000 --> 02:38.000
And it's a nice mix of Free Software and people coming together

02:38.000 --> 02:41.000
and discussing for two days, yeah, these exciting topics.

02:41.000 --> 02:45.000
And that's why we are going there since a couple of years

02:45.000 --> 02:50.000
and attending this conference with quite a lot of SFE people,

02:50.000 --> 02:54.000
volunteers, but also people from our office who work for the SFE.

02:54.000 --> 02:58.000
We also have a booth there where we can interact and chat with people

02:58.000 --> 02:59.000
who drop by.

02:59.000 --> 03:04.000
And it's not only interesting to hear and see the conference program

03:05.000 --> 03:10.000
and the exciting talks, but also to have chats at the booth afterwards

03:10.000 --> 03:13.000
where we can interact with our community, but also with people

03:13.000 --> 03:17.000
who never heard about the SFE, which are normally non,

03:17.000 --> 03:21.000
but yeah, so you have a lot of exchange,

03:21.000 --> 03:23.000
also others have booths there.

03:23.000 --> 03:27.000
And it's a very chaty conference where you can network a lot

03:27.000 --> 03:31.000
and where you can learn a lot about topics people work on these days

03:31.000 --> 03:33.000
when it comes to Free Software.

03:33.000 --> 03:36.000
And I said this year, many about ethics,

03:36.000 --> 03:39.000
but for us, super interesting, especially in the times

03:39.000 --> 03:41.000
that we are living in at the moment.

03:41.000 --> 03:43.000
Well, how was this displayed?

03:43.000 --> 03:45.000
That ethics was the main topic there,

03:45.000 --> 03:49.000
were there dedicated talks or, yeah, but...

03:49.000 --> 03:50.000
Yeah, absolutely.

03:50.000 --> 03:54.000
So there are also like several parallel tracks and sessions,

03:54.000 --> 03:59.000
so you have a couple of rooms, also like room for keynotes

03:59.000 --> 04:01.000
and you have virtual rooms.

04:01.000 --> 04:04.000
And if you take part in the call for papers,

04:04.000 --> 04:08.000
you normally also have to explain why this topic contributes

04:08.000 --> 04:11.000
to like the main topic of the conference of this year,

04:11.000 --> 04:12.000
which was ethics.

04:12.000 --> 04:14.000
So when you take part in the call for papers,

04:14.000 --> 04:17.000
you already have to think about why is this an important topic

04:17.000 --> 04:20.000
for the main issue that they want to discuss.

04:20.000 --> 04:23.000
However, there are also general talks about Free Software.

04:23.000 --> 04:26.000
So not everything is around ethics,

04:26.000 --> 04:31.000
but you see a lot of talks and workshops and conversations,

04:31.000 --> 04:34.000
panel discussions around those topics,

04:34.000 --> 04:36.000
in particular, in the main track.

04:36.000 --> 04:40.000
People share their views on this specific topic.

04:40.000 --> 04:44.000
And so you really feel that it's an important topic

04:44.000 --> 04:47.000
for the conference and that it's not just a theme

04:47.000 --> 04:49.000
or not just a saying,

04:49.000 --> 04:53.000
but that really people that then discuss these kinds of issues.

04:53.000 --> 04:54.000
All right.

04:54.000 --> 04:57.000
You already mentioned that there was a panel.

04:57.000 --> 05:02.000
So can you tell me a bit more about this panel?

05:02.000 --> 05:05.000
It is called ethics and software freedom.

05:05.000 --> 05:10.000
So what was it all about and who was part of this?

05:10.000 --> 05:12.000
Yeah, it was super interesting.

05:12.000 --> 05:14.000
Panel since it was Karen Sandler,

05:14.000 --> 05:18.000
it was Simon Phipps and our president Matthias Kirschner.

05:18.000 --> 05:20.000
And so we had very experienced people there on the panel,

05:20.000 --> 05:23.000
but also people who are in this field of resources

05:23.000 --> 05:26.000
and software since basically forever, if you like,

05:26.000 --> 05:29.000
since decades and who have really a lot of experience,

05:29.000 --> 05:33.000
who have seen a lot of debates already happening around Free Software

05:33.000 --> 05:36.000
and that are familiar not only with the recent debates

05:36.000 --> 05:38.000
and the general concept,

05:38.000 --> 05:41.000
but who really made up their mind about these topics.

05:41.000 --> 05:43.000
Yeah, so since since basically forever.

05:43.000 --> 05:45.000
And that was super interesting.

05:45.000 --> 05:49.000
There was not that much of a controversial debate.

05:49.000 --> 05:51.000
One can maybe also expect,

05:51.000 --> 05:54.000
however, there was a lot of like stories they told

05:54.000 --> 05:57.000
and it was super interesting to see how these debates

05:57.000 --> 06:00.000
on also already happened a couple of years

06:00.000 --> 06:04.000
or even decades ago and that it's just coming over and over again.

06:04.000 --> 06:06.000
Just this like different view.

06:06.000 --> 06:08.000
And one of these stories, for example,

06:08.000 --> 06:11.000
that Simon Phipps from the open source initiative shared there

06:11.000 --> 06:14.000
was that there is always this discussion

06:14.000 --> 06:18.000
about ethical licensing that you restrict the use case of Free Software

06:18.000 --> 06:21.000
and I think they all agree on that Free Software

06:21.000 --> 06:24.000
is coming without any restriction in particular

06:24.000 --> 06:26.000
when it comes about the use case.

06:26.000 --> 06:29.000
And however, we often see that people discuss,

06:29.000 --> 06:34.000
shouldn't we include some sort of like ethical use cases

06:34.000 --> 06:36.000
or like use cases that you,

06:36.000 --> 06:39.000
and for big people to use your Free Software,

06:39.000 --> 06:43.000
for example, when it comes to war or criminal activities,

06:43.000 --> 06:46.000
we also see there's a lot in AI up now

06:46.000 --> 06:49.000
that they say only for research or something like this.

06:49.000 --> 06:54.000
And normally there are morally good reasons

06:54.000 --> 06:59.000
to have this idea and people don't want something bad, right?

06:59.000 --> 07:02.000
And that's normally something good, right?

07:02.000 --> 07:04.000
So they make up their mind and they think,

07:04.000 --> 07:08.000
right, so I don't want that my software is then later

07:08.000 --> 07:11.000
be integrated in a tank or something like this.

07:11.000 --> 07:14.000
But however, the story that Simon, for example, shared

07:14.000 --> 07:17.000
was that back in the days, people, for example,

07:17.000 --> 07:20.000
when there was the apartheid system in South Africa,

07:20.000 --> 07:24.000
they said, look, every governmental organization in South Africa

07:24.000 --> 07:26.000
can't use our Free Software.

07:26.000 --> 07:30.000
And after the system changed, the license stayed.

07:30.000 --> 07:35.000
So this means that even maybe good people couldn't use the Free Software

07:35.000 --> 07:38.000
since it was in the license and it was kind of like

07:38.000 --> 07:41.000
if you like hard coded there and it couldn't be changed.

07:41.000 --> 07:44.000
And that makes it complicated in the long one.

07:44.000 --> 07:49.000
So what might be a good idea today might not be a good idea tomorrow

07:49.000 --> 07:54.000
since system change, idea change, discussion change.

07:54.000 --> 07:59.000
And that was I think a nice story to showcase

07:59.000 --> 08:04.000
why it is so important to not restrict the use case.

08:04.000 --> 08:09.000
And even if you might have a good reasoning or like a good idea

08:10.000 --> 08:14.000
or like, yeah, you want to do something good for the world, right?

08:14.000 --> 08:18.000
And you only want that software you created is only used

08:18.000 --> 08:20.000
for good purposes.

08:20.000 --> 08:23.000
This might backfire also one day later.

08:23.000 --> 08:26.000
So and therefore, yeah, it was an interesting story

08:26.000 --> 08:29.000
that I think had a lot of people to understand

08:29.000 --> 08:33.000
why it is so important to not restrict the use case.

08:33.000 --> 08:37.000
And also why it is then not Free Software anymore

08:37.000 --> 08:39.000
and we restrict the use case.

08:39.000 --> 08:42.000
And this panel wasn't this regard very interesting.

08:42.000 --> 08:46.000
So even if it was not controversial, I think it had a lot

08:46.000 --> 08:51.000
to understand why it is so important to think about ethics,

08:51.000 --> 08:55.000
to discuss ethics, to also have like a moral compass

08:55.000 --> 08:59.000
and I mean also we in FSFE having moral ideas right.

08:59.000 --> 09:03.000
So and we follow, so we are charity rights

09:03.000 --> 09:06.000
or we want to empower users to control technology

09:06.000 --> 09:08.000
which is our mission statement, for example,

09:08.000 --> 09:12.000
but still we also fight that the use case is not restricted

09:12.000 --> 09:14.000
and the Free Software remains Free Software.

09:14.000 --> 09:19.000
And I think for people who are not that much familiar with the

09:19.000 --> 09:22.000
debate or the backgrounds on all of the debates,

09:22.000 --> 09:26.000
it was very helpful to understand why this is not a good idea

09:26.000 --> 09:28.000
to restrict the use case.

09:28.000 --> 09:33.000
So and ultimately also to believe when we discuss these kinds

09:33.000 --> 09:37.000
of restrictions, one should also always know

09:37.000 --> 09:40.000
that we ultimately talk about the license right.

09:40.000 --> 09:44.000
So and if you as you just mentioned talk about criminal activities

09:44.000 --> 09:47.000
then these people already do not follow the law

09:47.000 --> 09:49.000
since they are criminals right.

09:49.000 --> 09:53.000
Very unlikely that they will be then stopped by a license

09:53.000 --> 09:55.000
with their activities right.

09:55.000 --> 09:57.000
So and this is also someone should consider

09:57.000 --> 10:02.000
and you then might also be understand why there might be

10:02.000 --> 10:05.000
more downsides if you restrict the use case

10:05.000 --> 10:07.000
that might backfire one day.

10:07.000 --> 10:09.000
And that's why it's not a good idea.

10:09.000 --> 10:12.000
And also you might not stop the people you want to stop.

10:12.000 --> 10:15.000
Was there also, I find this very interesting.

10:15.000 --> 10:19.000
I'm just wondering now because one I have always here

10:19.000 --> 10:26.000
in this context is that it's very much a social problem

10:26.000 --> 10:31.000
or a problem of our society and it needs to be solved

10:31.000 --> 10:32.000
within the society.

10:32.000 --> 10:36.000
It can't be solved by putting a license to something

10:36.000 --> 10:41.000
or by putting a restricting software use cases

10:41.000 --> 10:45.000
but it needs to be tackled as a society.

10:45.000 --> 10:50.000
And there is always this belief or this thought

10:50.000 --> 10:55.000
that if we put technology there then we will solve the problems.

10:55.000 --> 10:59.000
So like if we have robots cleaning everything

10:59.000 --> 11:02.000
then we won't have any debates anymore

11:02.000 --> 11:05.000
about who is doing the household for example

11:05.000 --> 11:07.000
because then the robot are doing it.

11:07.000 --> 11:09.000
But this isn't true.

11:09.000 --> 11:12.000
It will still be a debate and it will still shift.

11:12.000 --> 11:14.000
And you still need to think about this.

11:14.000 --> 11:16.000
It's now a very minor focus.

11:16.000 --> 11:19.000
But you still need to think about this as a society

11:19.000 --> 11:21.000
or a social problem.

11:21.000 --> 11:24.000
Was this argument discussed there at all?

11:24.000 --> 11:26.000
Absolutely.

11:26.000 --> 11:31.000
Also the classical debate which you have around tools.

11:31.000 --> 11:35.000
So you have a hammer and you can use it to have a tool

11:35.000 --> 11:37.000
which helps you, I don't know, build a house.

11:37.000 --> 11:40.000
But also you can use the hammer to kill someone.

11:40.000 --> 11:43.000
And to put a license restriction on the hammer

11:43.000 --> 11:47.000
to not use it for killing might be a bit useless

11:47.000 --> 11:50.000
if you then end up in prison anyhow.

11:50.000 --> 11:52.000
And it won't stop people from killing

11:52.000 --> 11:54.000
if you just put it in a license.

11:54.000 --> 11:57.000
So and it's more of a social problem.

11:57.000 --> 12:00.000
However, I would then also argue that

12:00.000 --> 12:04.000
this argument has a limit when we talk about weapons rights

12:04.000 --> 12:08.000
or if you might have weapons for hunters.

12:08.000 --> 12:11.000
But if you look at U.S. rights

12:11.000 --> 12:15.000
where people can buy crazy guns and just through the round

12:15.000 --> 12:18.000
then this also has to some extent some limits there.

12:18.000 --> 12:21.000
And you also should think about there

12:21.000 --> 12:25.000
to which extent we want to allow freedom

12:25.000 --> 12:27.000
when it comes to those kinds of,

12:27.000 --> 12:30.000
yeah, I wouldn't even consider this then as a tool anymore.

12:30.000 --> 12:32.000
But you're absolutely right.

12:32.000 --> 12:34.000
So we have in general social problems

12:34.000 --> 12:37.000
and we have to face them as a society

12:37.000 --> 12:40.000
and we can't stop the society

12:40.000 --> 12:42.000
or we can't change the society

12:42.000 --> 12:44.000
just as a license change.

12:44.000 --> 12:47.000
So there's absolutely way more.

12:47.000 --> 12:50.000
And I think this is also what we do in the FSI with our work.

12:50.000 --> 12:53.000
So we do not only promote a license

12:53.000 --> 12:56.000
and we do not only talk about different social license

12:56.000 --> 12:58.000
but we also talk about values.

12:58.000 --> 12:59.000
We talk about ideas.

12:59.000 --> 13:00.000
We talk about concepts.

13:00.000 --> 13:03.000
We talk about consumer protection, for example.

13:03.000 --> 13:06.000
And these are completely other debates

13:06.000 --> 13:08.000
than just talking about a license.

13:08.000 --> 13:11.000
And I think this is then also what we figured out

13:11.000 --> 13:12.000
during that conference.

13:12.000 --> 13:15.000
So that it's not only or that we,

13:15.000 --> 13:17.000
that we ultimately not only talk about

13:17.000 --> 13:19.000
a Free Software license

13:19.000 --> 13:21.000
or the restriction of use case,

13:21.000 --> 13:23.000
but that there is way more on

13:23.000 --> 13:25.000
how we need to think about this.

13:25.000 --> 13:27.000
So and many, many,

13:27.000 --> 13:29.000
like not only also independent,

13:29.000 --> 13:31.000
but also many talks then

13:31.000 --> 13:33.000
adjust the topic of AI

13:33.000 --> 13:36.000
where we more and more see these questions arising.

13:36.000 --> 13:38.000
So do we, how do we,

13:38.000 --> 13:40.000
how do we want to live with AI?

13:40.000 --> 13:42.000
That's not a license question, right?

13:42.000 --> 13:45.000
So that's where a social question

13:45.000 --> 13:47.000
that's a question for our society,

13:47.000 --> 13:48.000
that's a question for our,

13:48.000 --> 13:49.000
it's a global question,

13:49.000 --> 13:52.000
how we, how we want to address this.

13:52.000 --> 13:54.000
So and the opinion and just started

13:54.000 --> 13:56.000
with the AI act to regulate it.

13:56.000 --> 13:58.000
And we also have there,

13:58.000 --> 14:00.000
and we just recently had a podcast on this one.

14:00.000 --> 14:04.000
So on the, on the exemptions on Free Software in AI.

14:04.000 --> 14:06.000
But however, with this,

14:06.000 --> 14:07.000
we are, we are,

14:07.000 --> 14:10.000
we not reach the final point of regulating AI

14:10.000 --> 14:14.000
or we didn't like end the debate on how we look at AI.

14:15.000 --> 14:16.000
It, I would rather say,

14:16.000 --> 14:20.000
this is, this is the starting point for the debate around AI

14:20.000 --> 14:22.000
and how we want to live with this.

14:22.000 --> 14:24.000
And it's, it's not just a license question.

14:24.000 --> 14:26.000
So it, this is way, way more.

14:26.000 --> 14:28.000
And, and also Essex are,

14:28.000 --> 14:29.000
it's, it's also a term,

14:29.000 --> 14:31.000
like what means Essex to you,

14:31.000 --> 14:33.000
to me, to someone from the US,

14:33.000 --> 14:34.000
from China,

14:34.000 --> 14:36.000
from Latin America,

14:36.000 --> 14:38.000
why so different cultures look differently

14:38.000 --> 14:40.000
at some questions in the world.

14:40.000 --> 14:43.000
And Essex is also not really a,

14:43.000 --> 14:46.000
a term which is clearly defined, right?

14:46.000 --> 14:48.000
So where we all agree or not,

14:48.000 --> 14:49.000
where we all can say,

14:49.000 --> 14:50.000
yeah, this is the true,

14:50.000 --> 14:51.000
the true way here,

14:51.000 --> 14:53.000
or this is, this is the path we need to go.

14:53.000 --> 14:55.000
No, it's, it's about discussions.

14:55.000 --> 14:58.000
It's, it's about finding our ways

14:58.000 --> 15:03.000
to, to handling global social and societal questions,

15:03.000 --> 15:06.000
which, which can't be addressed just as a,

15:06.000 --> 15:07.000
as a license.

15:07.000 --> 15:08.000
However,

15:08.000 --> 15:09.000
and I,

15:09.000 --> 15:12.000
I also do believe that ultimately we should have,

15:12.000 --> 15:13.000
in particular,

15:13.000 --> 15:15.000
when we talk about AI Free Software,

15:15.000 --> 15:18.000
since this helps us to better understand what's happening there,

15:18.000 --> 15:22.000
to, to better understand where we could go with this.

15:22.000 --> 15:24.000
And this helps us to debate around this,

15:24.000 --> 15:26.000
since we have way more,

15:26.000 --> 15:27.000
for example, transparency,

15:27.000 --> 15:28.000
and, and by thus,

15:28.000 --> 15:29.000
we can,

15:29.000 --> 15:33.000
they better understand how to live and handle this.

15:33.000 --> 15:34.000
And, and that's why the,

15:34.000 --> 15:37.000
the Free Software license in this regard is important.

15:37.000 --> 15:38.000
And we should value it.

15:38.000 --> 15:39.000
However,

15:39.000 --> 15:41.000
it won't help us to fix

15:41.000 --> 15:44.000
all the evil in the world.

15:44.000 --> 15:46.000
That's a nice sentence.

15:46.000 --> 15:47.000
All right.

15:47.000 --> 15:50.000
I hear that there was more happening, actually,

15:50.000 --> 15:52.000
than this panel.

15:52.000 --> 15:54.000
Yeah, absolutely.

15:54.000 --> 15:57.000
Which I'm quite sure there will be a recording

15:57.000 --> 16:00.000
and the recording hopefully will be released soon

16:00.000 --> 16:03.000
and we will link to it in the show notes.

16:03.000 --> 16:04.000
Absolutely.

16:04.000 --> 16:05.000
And also,

16:05.000 --> 16:08.000
but the super interesting is that already decides

16:08.000 --> 16:10.000
are already there from all the talks

16:10.000 --> 16:12.000
on the panel discussion, obviously not.

16:12.000 --> 16:13.000
But also from the talks,

16:13.000 --> 16:15.000
the slides are already available.

16:15.000 --> 16:17.000
So you can click through them.

16:17.000 --> 16:20.000
Normally they are also quite quick in releasing the videos.

16:20.000 --> 16:22.000
And you will find them.

16:22.000 --> 16:23.000
The talks we,

16:23.000 --> 16:24.000
where we have been around,

16:24.000 --> 16:27.000
you will also find them on https://media.fsfe.org.

16:27.000 --> 16:30.000
But also we will find them on the social media channels

16:30.000 --> 16:31.000
of the SFS,

16:31.000 --> 16:32.000
S, Scon itself.

16:32.000 --> 16:35.000
And there have been way more interesting debates.

16:35.000 --> 16:36.000
We had,

16:36.000 --> 16:37.000
for example,

16:37.000 --> 16:39.000
debates about the feedback.

16:39.000 --> 16:40.000
There have been,

16:40.000 --> 16:43.000
I myself gave a talk about the funding topic,

16:43.000 --> 16:46.000
which you also addressed here in the podcast.

16:46.000 --> 16:49.000
My colleague Johannes talked about the procurement,

16:49.000 --> 16:51.000
reform, public money, public code,

16:51.000 --> 16:53.000
what to expect there.

16:53.000 --> 16:57.000
My colleague Darryl talked about route of freedom in Italy.

16:57.000 --> 16:58.000
Lucas,

16:58.000 --> 16:59.000
we all know him,

16:59.000 --> 17:00.000
the fighter for the M.A.

17:00.000 --> 17:02.000
And the apple case,

17:02.000 --> 17:08.000
where he fights about software freedom in front of the ECJ.

17:08.000 --> 17:10.000
So there have been also,

17:10.000 --> 17:12.000
and other super interesting talks,

17:12.000 --> 17:15.000
I said it's a two day conference with many talks,

17:15.000 --> 17:16.000
many stages,

17:16.000 --> 17:17.000
and many,

17:17.000 --> 17:19.000
many parallel tracks.

17:19.000 --> 17:21.000
So there's really a lot to see.

17:21.000 --> 17:23.000
And even I was not able to,

17:23.000 --> 17:26.000
to see all the talks that I wanted to see,

17:26.000 --> 17:28.000
since I said something happened parallel,

17:28.000 --> 17:32.000
or you have been in a meeting or in a chat with someone.

17:32.000 --> 17:34.000
It was so interesting that you,

17:34.000 --> 17:35.000
that you missed a talk.

17:35.000 --> 17:36.000
So,

17:36.000 --> 17:37.000
and yeah,

17:37.000 --> 17:41.000
the recordings definitely help to catch up with all the interesting debates there.

17:41.000 --> 17:43.000
Also some practical questions,

17:43.000 --> 17:44.000
so a talk,

17:44.000 --> 17:47.000
which I really liked a lot was one by Alexios,

17:47.000 --> 17:51.000
who is also part of our Youth Hacking 4 Freedom competition.

17:51.000 --> 17:53.000
He's working for Intel,

17:53.000 --> 17:54.000
and he talked, for example,

17:54.000 --> 17:58.000
about how to handle AI in the OSPOL in the company.

17:58.000 --> 17:59.000
So,

17:59.000 --> 18:01.000
so in the open source program office.

18:01.000 --> 18:03.000
So what do you need to do?

18:03.000 --> 18:04.000
And what does it mean,

18:04.000 --> 18:05.000
basically in reality,

18:05.000 --> 18:07.000
and how do people who work there?

18:07.000 --> 18:09.000
Then handle these problems.

18:09.000 --> 18:10.000
If they are,

18:10.000 --> 18:11.000
ending up at their desk,

18:11.000 --> 18:12.000
right,

18:12.000 --> 18:13.000
so often we discuss AI.

18:13.000 --> 18:15.000
I would say from a,

18:15.000 --> 18:16.000
from a bit far away,

18:16.000 --> 18:17.000
so we have vague ideas.

18:17.000 --> 18:18.000
And so,

18:18.000 --> 18:19.000
and so,

18:19.000 --> 18:20.000
and so,

18:20.000 --> 18:21.000
and so,

18:21.000 --> 18:22.000
and so,

18:22.000 --> 18:23.000
and so,

18:23.000 --> 18:24.000
and so,

18:24.000 --> 18:25.000
and so,

18:25.000 --> 18:26.000
and so,

18:26.000 --> 18:27.000
and so,

18:27.000 --> 18:28.000
and so,

18:28.000 --> 18:29.000
and so,

18:29.000 --> 18:30.000
and so,

18:30.000 --> 18:31.000
and so,

18:32.000 --> 18:33.000
and so,

18:33.000 --> 18:35.000
that differently.

18:35.000 --> 18:37.000
So we have vague ideas,

18:37.000 --> 18:38.000
and so we have vague ideas.

18:38.000 --> 18:42.000
And there

18:42.000 --> 18:44.000
and this told me I have seen someone who's not necessarily coming

18:44.000 --> 18:48.000
with AI but it's being confronted with the AI that he needs

18:48.000 --> 18:49.000
to handle in his OSPOL,

18:49.000 --> 18:50.000
and there was also super interesting talk.

18:50.000 --> 18:51.000
So there are many,

18:51.000 --> 18:53.000
many different talks that,

18:53.000 --> 18:55.000
that were super interesting.

18:55.000 --> 18:56.000
And not only covering ethics,

18:56.000 --> 18:58.000
but also practical issues.

18:58.000 --> 19:04.720
many children showed up where there was the other readings, why so much here for this

19:04.720 --> 19:11.600
children book, this other, so where these children were running around and reading the book

19:11.600 --> 19:16.480
and then they had a programming session where they learned programming and then they had ice

19:16.480 --> 19:22.640
creams and they had popcorn. So it was also that there were some really nice moments at this conference

19:22.640 --> 19:29.760
which was really nice which you maybe won't find at the recordings. Yeah it's children's

19:30.240 --> 19:33.520
but anyhow so also this happened at this conference or it was not just like

19:34.240 --> 19:40.240
professionals talking about their business but also yeah many emotional moments that happened

19:40.240 --> 19:46.240
at this conference that made it very nice to be there so if you haven't been to this conference

19:47.040 --> 19:51.520
then I can just highly recommend to go there next year it's also always happening

19:51.600 --> 19:55.600
in the beginning of November I'm not really sure about the next date but if you go to the

19:55.600 --> 20:01.280
website of the SFSCON they might release the date or already have released the date for the next

20:01.280 --> 20:08.160
year and it's definitely happening in the beginning of November. It's the 13th and 14th of November

20:08.160 --> 20:15.520
2026. This is the date. Mark this take part in the call for papers and even if you are not around

20:15.520 --> 20:20.560
there as a speaker I'll go there as a participant it's a really nice conference and also

20:20.560 --> 20:27.040
personally I have to say I like the area a lot there are many mountains so if you if you have

20:27.040 --> 20:33.120
the chance to stay one day longer I can highly recommend to visit the area there I go for a hike

20:33.120 --> 20:37.840
go in the mountains it's just so lovely there and yeah that makes it a really nice conference

20:37.840 --> 20:44.000
with a nice experience not only at the conference but where you can also spend some free time

20:44.000 --> 20:48.160
in the mountains which makes it at least for me very very nice conference. It sounds a bit like

20:48.240 --> 20:53.600
there's a lot of community that you experience there and that comes together and yeah

20:54.880 --> 21:00.160
exchanges ideas about Free Software about current debates and just

21:02.080 --> 21:09.040
enjoys to network or to talk with each other. Absolutely and normally always for auto run into

21:09.040 --> 21:14.720
new people and and hear about new ideas so and this is like auto in the evenings in the bars

21:15.360 --> 21:21.920
it's it's it's just nice to yeah meet people exchange and have a have a really nice time there

21:22.480 --> 21:30.160
and normally you also learn a bit or even a bit more and that makes it yeah very nice experience

21:30.160 --> 21:37.040
to go there. Was there something that stood out to you a lot? Timers running fast I know you

21:37.040 --> 21:42.640
already mentioned the best talk you attended or one of the best that you attended as you

21:43.520 --> 21:48.880
as you also sounded it was like a very busy conference there but was there something that stood

21:48.880 --> 21:56.480
out to you and that you wanted to share with our listeners? I do believe it it was also the

21:56.480 --> 22:03.360
conversations I had after my talk on funding but also Jordan from from the also the

22:03.360 --> 22:08.560
negative impact on the cyber resilience act and this is still something which you which you

22:08.560 --> 22:14.960
see a lot being discussed there on these kind of conferences too where people discuss the topic

22:14.960 --> 22:20.800
of funding so and this is something which is it's a lot around the discussion so cyber resilience

22:20.800 --> 22:29.200
act new regulations but also we see that we have issues with core infrastructure but also on the

22:29.280 --> 22:36.400
other hand innovation procurement so whenever we talk about these kind of topics ultimately you see

22:36.400 --> 22:43.680
people in the end talking about funding and money and this is something where I really do believe

22:43.680 --> 22:49.840
that yeah this is our this is our call for a secured long term funding for the software which is

22:50.960 --> 22:56.400
pulled by private and public money is something which we really need to follow up and where we

22:57.120 --> 23:03.360
was good that we started this initiative some yeah I'd say now years ago to think about

23:03.360 --> 23:08.960
these important questions because it's more and more arising and becoming more and more clear

23:08.960 --> 23:15.920
that we need to address these issues and also what I really liked added to this is that I had

23:15.920 --> 23:22.080
a conversation with Sebastian from Appel that he not only have to think about funding but also

23:22.720 --> 23:30.160
mental health maybe of the people in our community so often we see people that maybe run into burnouts

23:30.160 --> 23:38.000
or that are facing so many problems with their projects that they might be overwhelmed with

23:38.000 --> 23:42.400
whatever they do and I also do believe that this is something where we where we need to have an

23:42.400 --> 23:50.400
eye on that we that we make sure that our community yeah it's not burning out at one point but that

23:50.400 --> 23:56.080
we also not only value their work and in this regard I think it was also super nice that we had

23:56.080 --> 24:02.320
the software freedom awards which this year also came when to to real see a very nice community

24:02.320 --> 24:06.880
project but ultimately it's not only about value in the world but that we also think about more of

24:06.880 --> 24:13.520
like in a way of like sustaining project or to have sustainable project that we that we look

24:13.520 --> 24:17.920
not only at the project but at the people behind and I also do believe that this is something

24:18.000 --> 24:23.120
what you're doing we see we see a lot for software day and in particular like for the next

24:23.120 --> 24:28.240
edition it's very very want to thank maintainers that this is something which is absolutely going

24:28.240 --> 24:33.040
in the right direction and which is addressing also some of these issues which we which we sometimes

24:33.040 --> 24:39.280
do not see or which we do not value that much that there are people behind this and that these people

24:39.280 --> 24:44.960
sometimes really struggle and that we the bare minimum is that we thank them but that we also

24:44.960 --> 24:50.720
think about like how can we make this all a more cozy environment so to say how can we secure

24:50.720 --> 24:55.520
the future of Free Software yeah absolutely I like that and I will take that as a closing word

24:55.520 --> 25:02.560
because time is running so fast again Alex yes thank you so much thank you thank you for having

25:02.560 --> 25:08.320
me it was as always as well as a real pleasure and I'm so happy that you took the time that you

25:09.120 --> 25:15.920
shared your experience from the software SFSCON from the software freedom conference in

25:15.920 --> 25:25.520
Bolzano yeah thanks so much thank you bunny this was the software freedom podcast if you liked

25:25.520 --> 25:31.520
this episode please recommend it to your friends and rate it stay tuned for more inspiring

25:31.520 --> 25:37.600
conversations that explore the importance of software freedom and its impact on our digital lives

25:38.480 --> 25:44.640
this podcast is presented to you by the Free Software foundation Europe and BR charity that

25:44.640 --> 25:50.720
works on promoting software freedom if you like our work please consider supporting us

25:50.720 --> 25:58.640
with our donation you find more information under fsfe.org slash donate thank you so much for

25:58.640 --> 26:02.480
listening and see you next month thank you so much

26:09.280 --> 26:24.240
hey I'm Alex senior policy consultant from the Free Software Foundation Europe one of my favorite

26:24.240 --> 26:30.720
podcasts is Linux in laws i very much enjoyed their insightful discussions about Free Software

26:30.720 --> 26:35.680
and in the end i always have to love about their funny discussions so give them a try under

26:35.680 --> 26:37.680
linuxinlaws.eu

   
</div>

</pre>

<p><a href="/news/podcast/episode-41.html">Back to the episode SFP#41</a></p>

</body>
<sidebar promo="our-work">

</sidebar>
  
</html>
